{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "- check if .hscfg file in your home folder is correctly configured (see hsdsaccess_example.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = \"/SILICON_STUDY/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ramanchada2.spectrum import from_chada\n",
    "from ramanchada2.io.HSDS import visit_domain, filter_dataset, read_cha\n",
    "import math\n",
    "import h5pyd\n",
    "\n",
    "\n",
    "def load_dataset(parentdomain,domain,results=[],h5module=h5pyd):\n",
    "    with h5module.File(domain) as f:\n",
    "        wavelength = f[\"annotation_study\"].attrs[\"wavelength\"]\n",
    "        instrument = f[\"annotation_study\"].attrs[\"instrument\"]\n",
    "        laser_power = f[\"annotation_study\"].attrs[\"laser_power\"]\n",
    "        provider = f[\"annotation_study\"].attrs[\"provider\"]\n",
    "        sample = f[\"annotation_sample\"].attrs[\"sample\"]\n",
    "    results.append((domain,provider,instrument,wavelength,laser_power,sample))\n",
    "\n",
    "query_sample = \"S0N\"\n",
    "\n",
    "results = []\n",
    "# query by sample\n",
    "#visit_domain(study, process_dataset=filter_dataset,kwargs={\"process_file\" : load_dataset,\"sample\": query_sample, \n",
    "#                            \"kwargs\" : {\"results\" : results}})\n",
    "# retrieve everything under study\n",
    "visit_domain(study, process_dataset=load_dataset, kwargs = {\"results\" : results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results,columns=[\"domain\",\"provider\",\"instrument\",\"wavelength\",\"laser_power\",\"sample\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "#test follows, to be applied to all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = df[df[\"sample\"]==\"S0B\"].iloc[0][\"domain\"]\n",
    "\n",
    "\n",
    "def find_peaks_bgm(spe,n_components=3,max_iter=10000,n_samples=5000):\n",
    "    bgm = spe.bayesian_gaussian_mixture(n_samples=n_samples,  \n",
    "                n_components=n_components,\n",
    "                max_iter=max_iter,\n",
    "                moving_minimum_window=16,\n",
    "                random_state=42,\n",
    "                trim_range=None)\n",
    "    bgm_peaks = [[mean[0], np.sqrt(cov[0][0]), weight]\n",
    "                     for mean, cov, weight in\n",
    "                     zip(bgm.means_, bgm.covariances_, bgm.weights_)]\n",
    "    bgm_peaks = sorted(bgm_peaks, key=lambda x: x[2], reverse=True)\n",
    "    n_peaks = (np.round(bgm.weights_, 2) > 0).sum()\n",
    "    return bgm,bgm_peaks[:n_peaks]\n",
    "\n",
    "crop_range=[450,600]\n",
    "spe = from_chada(domain,h5module=h5pyd)\n",
    "spe = spe.trim_axes(\"x-axis\",crop_range)\n",
    "spe.plot()\n",
    "bgm,bgm_peaks = find_peaks_bgm(spe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_area(spe):\n",
    "    res = spe.y # - np.min(spe.y)\n",
    "    res /= (np.sum(res) * (spe.x[1]-spe.x[0]))\n",
    "    return res\n",
    "\n",
    "def plotdist(bgm,bgm_peaks,spe,threshold=0.00001):\n",
    "    #new_spe = spe.normalize('unity')\n",
    "    spe = spe - spe.moving_minimum(16)    \n",
    "    y_norm = normalize_area(spe)\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,2))\n",
    "    ax1.plot(spe.x,y_norm,':',label='spe')\n",
    "\n",
    "    _xrange = np.linspace(min(spe.x),max(spe.x),1000)\n",
    "    _tmp = None\n",
    "    for e in bgm_peaks:\n",
    "        weight = e[2]\n",
    "        if weight>=threshold:\n",
    "            mu = e[0]\n",
    "            sigma =e[1]\n",
    "            gm = stats.norm(mu, sigma)\n",
    "            if _tmp is None:\n",
    "                _tmp = weight*gm.pdf(spe.x)\n",
    "            else:\n",
    "                _tmp = _tmp + weight*gm.pdf(spe.x)\n",
    "            #print(_tmp)\n",
    "            ax1.scatter(mu, weight*gm.pdf(mu),label=e[1])\n",
    "            ax2.plot(spe.x,y_norm,':')\n",
    "            ax2.plot(_xrange, weight*gm.pdf(_xrange),'-')\n",
    "            \n",
    "            #ax2.plot(spe.x,new_spe.y,'*')\n",
    "    ax1.plot(spe.x,_tmp,'.')\n",
    "    #ax1.plot(_xrange,bgm.predict_proba(list(map(lambda x: [x], _xrange))),'.')\n",
    "    X,y = bgm.sample(100)\n",
    "    print(y)\n",
    "    #ax1.plot(list(map(lambda x: x[0], X)),y,'.')\n",
    "    return (ax1,ax2)\n",
    "\n",
    "print(bgm_peaks)\n",
    "plotdist(bgm,bgm_peaks,spe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(domain):\n",
    "    try:\n",
    "        print(domain)\n",
    "        crop_range=[450,600]\n",
    "        spe = from_chada(domain,h5module=h5pyd)\n",
    "        spe = spe.trim_axes(\"x-axis\",crop_range)\n",
    "        #spe.plot()\n",
    "        bgm,bgm_peaks = find_peaks_bgm(spe)\n",
    "        #apply peak finding tbd\n",
    "        res = []\n",
    "        for peak in bgm_peaks:\n",
    "            res.append(peak[0])\n",
    "            res.append(peak[1])\n",
    "            res.append(peak[2])\n",
    "        \n",
    "        return pd.Series(res)    \n",
    "\n",
    "    except Exception as err:\n",
    "        print(domain,err)\n",
    "        return pd.Series([None,None,None,None,None,None,None,None,None])\n",
    "\n",
    "cols = [\"peak1_mean\",\"peak1_sigma\",\"peak1_weight\",\"peak2_mean\",\"peak2_sigma\",\"peak2_weight\",\"peak3_mean\",\"peak3_sigma\",\"peak3_weight\"]\n",
    "#df[cols] = df[df[\"domain\"]==\"/SILICON_STUDY/ELODIZ/ELODIZ_NEEGALA/532/S0B-1_SEX139-532_Day1.cha\"].apply(lambda row: process_row(row[\"domain\"]),axis=1)\n",
    "\n",
    "df[cols] = df[df[\"sample\"]!=\"Neon\"].apply(lambda row: process_row(row[\"domain\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"silica.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.histogram(df.dropna(),x=\"peak1_mean\",nbins=100,facet_row=\"sample\",color=\"provider\",width=1200, height=600,template=\"simple_white\")\n",
    "fig.update_traces( textfont_size=8)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('charisma')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb04d3982f35e0acdef77e55e8b663fd61d1c7b237bd8280d18cbffb390c1e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
