{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "- check if .hscfg file in your home folder is correctly configured (see hsdsaccess_example.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5pyd\n",
    "\n",
    "def print_dataset(parentdomain,domain):\n",
    "    print(parentdomain,domain)\n",
    "\n",
    "def visit_domain(topdomain=\"/Round_Robin_1/\",process_dataset=None,kwargs={}):\n",
    "    if topdomain.endswith(\"/\"):\n",
    "        with h5pyd.Folder(topdomain) as domain:\n",
    "            n = domain._getSubdomains()\n",
    "            for domain in domain._subdomains:\n",
    "                #print(domain)\n",
    "                if domain[\"class\"]==\"folder\":\n",
    "                    visit_domain(\"{}/\".format(domain[\"name\"]),process_dataset,kwargs)\n",
    "                else:\n",
    "                    if process_dataset == None:\n",
    "                        print_dataset(topdomain,domain[\"name\"])\n",
    "                    else:\n",
    "                        process_dataset(topdomain,domain[\"name\"],**kwargs)\n",
    "    else:\n",
    "        if process_dataset == None:\n",
    "            print_dataset(None,topdomain)\n",
    "        else:\n",
    "            process_dataset(None,topdomain,**kwargs)        \n",
    "\n",
    "visit_domain(topdomain=\"/Round_Robin_1/\",process_dataset=print_dataset)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_dataset(topdomain,domain,process_file,sample=None,wavelength=None,instrument=None,provider=None,investigation=None):\n",
    "    with h5pyd.File(domain) as dataset:\n",
    "        if (sample != None) and (dataset[\"annotation_sample\"].attrs[\"sample\"] == sample):\n",
    "            process_file(topdomain,domain)\n",
    "\n",
    "def plot_dataset(topdomain,domain):\n",
    "    print_dataset(topdomain,domain)\n",
    "    with h5pyd.File(domain) as f:    \n",
    "        dset = f[\"raw\"]\n",
    "        plt.plot(dset[0],dset[1])\n",
    "        plt.xlabel(dset.dims[0].label)\n",
    "        plt.ylabel(dset.dims[1].label)\n",
    "        sample = f[\"annotation_sample\"].attrs[\"sample\"]\n",
    "        instrument = f[\"annotation_study\"].attrs[\"instrument\"]\n",
    "        wavelength = f[\"annotation_study\"].attrs[\"wavelength\"]\n",
    "        partner = f[\"annotation_study\"].attrs[\"provider\"]\n",
    "        investigation = f[\"annotation_study\"].attrs[\"investigation\"]\n",
    "        plt.suptitle(\"{} ({},{}nm) by {} [{}]\".format(sample, instrument, wavelength, partner, investigation))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sample=\"S0N\"\n",
    "query_sample=\"Neon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_domain(\"/Round_Robin_1/FMNT-Madrid/\",\n",
    "        process_dataset=filter_dataset,kwargs={\"process_file\" : plot_dataset,\"sample\": query_sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ramanchada2 as rc2\n",
    "test = \"/Round_Robin_1/ICV-CSIC/Zolix Finder Edge/785/PST02_Zolix785_Probe_100_190ms.cha\"\n",
    "test = \"/Round_Robin_1/ICV-CSIC/Zolix Finder Edge/785/Ne_785nm_Zolix_6ms_v2.cha\"\n",
    "test = \"/Round_Robin_1/FMNT-Madrid/BWTek iRaman/532/S0N10_iR532_Probe_100_30000msx3.cha\"\n",
    "spe = rc2.spectrum.from_chada(test,h5module=h5pyd)\n",
    "spe.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def find_peaks(topdomain,domain,results={}):\n",
    "    spe = rc2.spectrum.from_chada(domain,h5module=h5pyd)\n",
    "    spe = spe.normalize()\n",
    "    kw_sharpening = dict(filter_fraction=1, sig_width=.4, der2_factor=0, der4_factor=.1)\n",
    "    #kw_sharpening = dict(filter_fraction=.6, sig_width=.5, der2_factor=1, der4_factor=.1)\n",
    "    #sharpened = spe.subtract_moving_minimum(60).normalize().derivative_sharpening(**kw_sharpening)    \n",
    "    peak_candidates = spe.find_peak_groups(\n",
    "        prominence=.005,\n",
    "        wlen=40,\n",
    "        width=1,\n",
    "        n_sigma_group=1.5,\n",
    "        moving_minimum_window=40,\n",
    "        kw_derivative_sharpening=kw_sharpening) \n",
    "    fit_res = spe.fit_peak_groups(model='Voigt', peak_candidate_groups=peak_candidates) \n",
    "    results[domain] = fit_res         \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "visit_domain(test,\n",
    "        process_dataset=find_peaks,kwargs={\"results\": results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "for domain in results:\n",
    "    fit_res = results[domain]\n",
    "    tmp= pd.DataFrame(\n",
    "                [\n",
    "                    dict(name=f'g{group:02d}_{key}', value=val.value, stderr=val.stderr)\n",
    "                    for group, res in enumerate(fit_res)\n",
    "                    for key, val in res.params.items()\n",
    "                ]\n",
    "            )\n",
    "    tmp[\"source\"]=domain\n",
    "    if df == None:\n",
    "        df = tmp\n",
    "    else:\n",
    "        df = pd.concat([df, tmp]) \n",
    "df[['group', 'model', 'param']]=df[\"name\"].str.split(\"_\", expand=True)        \n",
    "display(df)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "_filter = df[\"model\"]!=\"bl\"\n",
    "table = pd.pivot_table(df.loc[_filter], values=['value','stderr'], index=['source','group', 'model'],columns=['param'],\n",
    "                    aggfunc={'value': np.mean, 'stderr' : np.mean}).reset_index()\n",
    "table.columns = [' '.join(col).strip() for col in table.columns.values]\n",
    "table_stats = table.describe()         \n",
    "table_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_filter1 = table[\"value amplitude\"] > table_stats.iloc[6][\"value amplitude\"]\n",
    "_filter2 = table[\"value height\"] > table_stats.iloc[6][\"value height\"]\n",
    "table_filtered = table.loc[_filter1 & _filter2]\n",
    "fig = px.scatter(table_filtered, x=\"value center\", y=\"stderr center\")\n",
    "fig.show()\n",
    "display(table_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PST_peaks = (621,795,1001,1031,1155,1450,1583,1602)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ramanchada2",
   "language": "python",
   "name": "ramanchada2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb04d3982f35e0acdef77e55e8b663fd61d1c7b237bd8280d18cbffb390c1e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
